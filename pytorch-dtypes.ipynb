{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Function to set the number of CPU threads\n",
    "def set_cpu_thread_cap(num_threads):\n",
    "    torch.set_num_threads(num_threads)\n",
    "    torch.set_num_interop_threads(num_threads)\n",
    "    print(f\"Set max CPU threads to: {num_threads}\")\n",
    "\n",
    "def probe_device_dtypes(device):\n",
    "\n",
    "    # If running on CPU, set the number of threads\n",
    "    if device == 'cpu':\n",
    "        set_cpu_thread_cap(30)  # Set this to the desired number of CPU threads\n",
    "    \n",
    "    \"\"\"Dynamically probe the device for supported dtypes.\"\"\"\n",
    "    all_dtypes = [\n",
    "        torch.float64, torch.float32, torch.float16, torch.bfloat16,\n",
    "        torch.int8, torch.uint8, torch.int16, torch.int32, torch.int64,\n",
    "        torch.bool, torch.complex64, torch.complex128\n",
    "    ]\n",
    "    \n",
    "    supported_dtypes = []\n",
    "    matrix_size = 64  # Small size for quick probing\n",
    "    \n",
    "    for dtype in all_dtypes:\n",
    "        try:\n",
    "            if dtype in [torch.int8, torch.uint8, torch.int16, torch.int32, torch.int64]:\n",
    "                matrix_a = torch.randint(0, 100, (matrix_size, matrix_size), dtype=dtype).to(device)\n",
    "                matrix_b = torch.randint(0, 100, (matrix_size, matrix_size), dtype=dtype).to(device)\n",
    "            elif dtype == torch.bool:\n",
    "                matrix_a = torch.randint(0, 2, (matrix_size, matrix_size), dtype=dtype).to(device)\n",
    "                matrix_b = torch.randint(0, 2, (matrix_size, matrix_size), dtype=dtype).to(device)\n",
    "            elif dtype in [torch.complex64, torch.complex128]:\n",
    "                matrix_a = torch.randn(matrix_size, matrix_size, dtype=dtype).to(device)\n",
    "                matrix_b = torch.randn(matrix_size, matrix_size, dtype=dtype).to(device)\n",
    "            else:\n",
    "                matrix_a = torch.rand(matrix_size, matrix_size, dtype=dtype).to(device)\n",
    "                matrix_b = torch.rand(matrix_size, matrix_size, dtype=dtype).to(device)\n",
    "            \n",
    "            _ = torch.matmul(matrix_a, matrix_b)\n",
    "            if \"cuda\" in device:\n",
    "                torch.cuda.synchronize()\n",
    "            elif \"xpu\" in device:\n",
    "                torch.xpu.synchronize()\n",
    "            \n",
    "            supported_dtypes.append(dtype)\n",
    "        except (RuntimeError, TypeError, AttributeError):\n",
    "            continue\n",
    "    \n",
    "    return supported_dtypes, [dt for dt in all_dtypes if dt not in supported_dtypes]\n",
    "\n",
    "def run_benchmark(device, dtype, matrix_size=4096, epochs=10, warmup_runs=2):\n",
    "    \"\"\"Run benchmark for a specific dtype on the given device.\"\"\"\n",
    "    if dtype in [torch.int8, torch.uint8, torch.int16, torch.int32, torch.int64]:\n",
    "        matrix_a = torch.randint(0, 100, (matrix_size, matrix_size), dtype=dtype).to(device)\n",
    "        matrix_b = torch.randint(0, 100, (matrix_size, matrix_size), dtype=dtype).to(device)\n",
    "    elif dtype == torch.bool:\n",
    "        matrix_a = torch.randint(0, 2, (matrix_size, matrix_size), dtype=dtype).to(device)\n",
    "        matrix_b = torch.randint(0, 2, (matrix_size, matrix_size), dtype=dtype).to(device)\n",
    "    elif dtype in [torch.complex64, torch.complex128]:\n",
    "        matrix_a = torch.randn(matrix_size, matrix_size, dtype=dtype).to(device)\n",
    "        matrix_b = torch.randn(matrix_size, matrix_size, dtype=dtype).to(device)\n",
    "    else:\n",
    "        matrix_a = torch.rand(matrix_size, matrix_size, dtype=dtype).to(device)\n",
    "        matrix_b = torch.rand(matrix_size, matrix_size, dtype=dtype).to(device)\n",
    "\n",
    "    # Warmup runs\n",
    "    for _ in range(warmup_runs):\n",
    "        _ = torch.matmul(matrix_a, matrix_b)\n",
    "    if \"cuda\" in device:\n",
    "        torch.cuda.synchronize()\n",
    "    elif \"xpu\" in device:\n",
    "        torch.xpu.synchronize()\n",
    "\n",
    "    # Main benchmark\n",
    "    start_time = time.time()\n",
    "    if \"cuda\" in device:\n",
    "        torch.cuda.synchronize()\n",
    "    elif \"xpu\" in device:\n",
    "        torch.xpu.synchronize()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        result = torch.matmul(matrix_a, matrix_b)\n",
    "        if \"cuda\" in device:\n",
    "            torch.cuda.synchronize()\n",
    "        elif \"xpu\" in device:\n",
    "            torch.xpu.synchronize()\n",
    "        if (epoch + 1) % 10 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Completed epoch {epoch + 1}/{epochs} for {str(dtype).split('.')[-1]}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    if \"cuda\" in device:\n",
    "        torch.cuda.synchronize()\n",
    "    elif \"xpu\" in device:\n",
    "        torch.xpu.synchronize()\n",
    "    \n",
    "    total_time = end_time - start_time\n",
    "    operations = matrix_size ** 3 * epochs\n",
    "    \n",
    "    # Handle zero or near-zero time to avoid division by zero\n",
    "    if total_time <= 0:\n",
    "        print(f\"Warning: Total time for {str(dtype).split('.')[-1]} was zero or negative, setting GOPS to 0\")\n",
    "        gops = 0.0\n",
    "    else:\n",
    "        gops = (operations / total_time) / 1e9\n",
    "    \n",
    "    return total_time, gops\n",
    "\n",
    "def run_multi_dtype_benchmark(device_str=\"cuda:0\", matrix_size=4096, epochs=10, warmup_runs=2, runs=1):\n",
    "    # Determine device\n",
    "    if \"cuda\" in device_str and torch.cuda.is_available():\n",
    "        device = device_str\n",
    "        device_name = torch.cuda.get_device_name(device)\n",
    "    elif \"xpu\" in device_str and hasattr(torch, \"xpu\") and torch.xpu.is_available():\n",
    "        device = device_str\n",
    "        device_name = torch.xpu.get_device_name(device)\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        device_name = \"CPU\"\n",
    "    \n",
    "    # Display initial info\n",
    "    print(f\"Running on: {device} ({device_name})\")\n",
    "    print(f\"Matrix size: {matrix_size}x{matrix_size}\")\n",
    "    print(f\"Epochs: {epochs}\")\n",
    "    print(f\"Warmup runs: {warmup_runs}\")\n",
    "    print(f\"Number of runs: {runs}\\n\")\n",
    "\n",
    "    # Probe supported dtypes\n",
    "    print(\"Probing device for supported dtypes...\")\n",
    "    supported_dtypes, unsupported_dtypes = probe_device_dtypes(device)\n",
    "    print(f\"Supported dtypes: {[str(dt).split('.')[-1] for dt in supported_dtypes]}\\n\")\n",
    "\n",
    "    # Store results across all runs\n",
    "    all_results = {dtype: {\"times\": [], \"gops_list\": []} for dtype in supported_dtypes}\n",
    "\n",
    "    # Run benchmarks multiple times\n",
    "    for run in range(runs):\n",
    "        print(f\"\\nRun {run + 1}/{runs}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for dtype in supported_dtypes:\n",
    "            print(f\"Running benchmark for {str(dtype).split('.')[-1]}\")\n",
    "            total_time, gops = run_benchmark(device, dtype, matrix_size, epochs, warmup_runs)\n",
    "            all_results[dtype][\"times\"].append(total_time)\n",
    "            all_results[dtype][\"gops_list\"].append(gops)\n",
    "            \n",
    "            # Print individual run stats\n",
    "            dtype_name = str(dtype).split('.')[-1]\n",
    "            print(f\"{dtype_name:<12} Total Time: {total_time:<6.2f}s  GOPS: {gops:<6.2f}\")\n",
    "\n",
    "    # Calculate and print averages\n",
    "    print(\"\\nAverage Benchmark Results Across All Runs:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Dtype':<12} {'Avg Total Time (s)':<20} {'Avg GOPS':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for dtype in supported_dtypes:\n",
    "        dtype_name = str(dtype).split('.')[-1]\n",
    "        avg_time = sum(all_results[dtype][\"times\"]) / runs\n",
    "        avg_gops = sum(all_results[dtype][\"gops_list\"]) / runs\n",
    "        print(f\"{dtype_name:<12} {avg_time:<20.2f} {avg_gops:<10.2f}\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Print supported and unsupported dtypes\n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"Supported dtypes: {[str(dt).split('.')[-1] for dt in supported_dtypes]}\")\n",
    "    print(f\"Unsupported dtypes: {[str(dt).split('.')[-1] for dt in unsupported_dtypes]}\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Example usage in notebook\n",
    "matrix_size = 4096\n",
    "epochs = 10\n",
    "warmup_runs = 10\n",
    "runs = 3  # Number of times to repeat the full benchmark\n",
    "device = \"cuda:0\"  # Change to \"xpu:0\" for Intel XPU or \"cpu\" as needed\n",
    "\n",
    "results = run_multi_dtype_benchmark(\n",
    "    device_str=device,\n",
    "    matrix_size=matrix_size,\n",
    "    epochs=epochs,\n",
    "    warmup_runs=warmup_runs,\n",
    "    runs=runs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
